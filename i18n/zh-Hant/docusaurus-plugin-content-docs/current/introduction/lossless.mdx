---
title: Lossless Compression
sidebar_position: 3
---

# Lossless Compression

:::info Under Maintenance
The content in this entry is incomplete & is in the process of being completed.
:::

無損壓縮是一種數據壓縮技術，能夠在壓縮後完全恢復原始數據。在需要完全保留原始內容完整性的應用場景中，這種技術尤為重要，例如在數據存檔、通用數據壓縮和專業媒體編輯中。為了理解無損壓縮的運作原理，我們首先需要了解冗餘、熵的概念，以及無損壓縮中常用的幾種壓縮技術。

### 冗餘與熵

了解冗餘與熵的概念對於深入理解無損壓縮至關重要。

**冗餘** 指的是數據中重複或可預測的部分。這些部分並不提供新信息，通過高效編碼可以減少數據大小，而不會損失任何信息。

**熵** 在信息理論中是用來衡量數據的隨機性或不可預測性。熵越低，冗餘度越高，意味著數據在理論上越容易壓縮。

在無損壓縮中，我們的目標是減少冗餘，並根據數據的熵進行最有效的編碼。


### 無損壓縮中的技術

1. **游程編碼 (run-length encoding,RLE)**：
   游程編碼是一種簡單的無損壓縮方法，將連續相同的數據值（即“游程”）儲存為單一數據值和計數。這種技術非常適合壓縮長時間重複的數據，例如靜音或恆定音調。例如，序列 `AAAAABBBCC` 可以被編碼為 `5A3B2C`。

2. **run-length encoding (Huffman Coding)**：
   霍夫曼編碼是一種熵編碼算法，用於無損數據壓縮。它通過將數據拆分為組成符號，並為每個符號分配編碼來工作。這個過程涉及構建一棵二叉樹，每個葉節點代表一個符號，從根到葉的路徑對應於該符號的二進制編碼。

   霍夫曼編碼在知道字符概率分佈的情況下效果最佳。假設你在記錄交通信號燈的狀態，它可能是綠色、黃色、紅色或因維修而關閉。根據統計，綠色出現的機率為 50%、紅色 40%、黃色 9%、關閉 1%。由於這裡有四種狀態，我們可以用兩位二進制數來表示。綠色可以用 `00`、紅色 `01`、黃色 `10`，關閉則為 `11`。然而，為了更有效地壓縮數據，我們可以根據各狀態的出現頻率分配編碼。例如，綠色頻率最高，所以分配 `0`，紅色 `11`，黃色 `100`，關閉 `101`。這樣，我們得到的霍夫曼編碼如下：
       - 綠色     (50%): `0`
       - 紅色     (40%): `11`
       - 黃色     ( 9%): `100`
       - 關閉     ( 1%): `101`

   樹形結構如下所示：

   ![交通信號燈霍夫曼樹](https://raw.githubusercontent.com/av1-community-contributors/images/main/color-huffman-tree-svg.svg)

   通過計算概率與編碼長度的加權總和：
       (50% • 1) + (40% • 2) + (9% • 3) + (1% • 3) = **1.6**

   我們得到每個符號的平均 **1.6 位**。這顯示了霍夫曼編碼在節省空間方面的高效性，同時能夠無損地保留信息。
3. **算術編碼**
   算術編碼是一種熵編碼技術，它將整個訊息表示為 `[0, 1)` 區間中的一個單一數字。與霍夫曼編碼不同的是，霍夫曼編碼為輸入中的每個符號分配固定的二進制碼，而算術編碼則使用一個範圍在 `0.0 ≤ q < 1.0` 之間的浮點數 *q* 來表示多個符號。當符號的概率分佈偏斜時，算術編碼能提供比霍夫曼編碼更緊湊的表示，但它的處理速度通常比霍夫曼編碼慢。

   讓我們回到交通信號燈的例子。如果你對之前霍夫曼編碼的結果不滿意，該結果的平均位元數為 1.6，而你希望使用算術編碼，則在算術編碼中，每個符號會首先根據其概率被分配到 `[0, 1)` 區間中的一個範圍。隨著我們編碼更多符號，這個範圍會逐漸縮小，最終得出一個單一數字來表示整個序列。具體步驟如下。
    Let's use the same probabilities from before:
    - Green     (50%)
    - Red       (40%)
    - Yellow    ( 9%)
    - Disabled  ( 1%)

    We'll assign ranges to each symbol as follows:

    - Green:    `[0.00, 0.50)`
    - Red:      `[0.50, 0.90)`
    - Yellow:   `[0.90, 0.99)`
    - Disabled: `[0.99, 1.00)`

    Now, let's encode a sequence of traffic light states: "Green, Red, Yellow, Green"

    1. Start with the interval `[0, 1)`

    2. First symbol (Green):
        - `new_low = low + (high - low) • cumulative(s) / total`
        - `new_high = low + (high - low) • (cumulative(s) + prob(s)) / total`
        - `new_low = 0 + (0.5 - 0) • 0 / 1.0`
        - `new_high = 0 + (0.5 - 0) • (0 + 0.5) / 1.0`
        - Narrow range to `[0.00, 0.50)`

    3. Second symbol (Red):
        - From previous range: `[0.00, 0.50)`
        - `new_low = 0 + (0.50 - 0) * 0.50 / 1`
        - `new_high = 0 + (0.50 - 0) * (0.50 + 0.40) / 1`
        - Red is in the range `[0.25, 0.45)`

    4. Third symbol (Yellow):
        - From previous range: `[0.25, 0.45)`
        - `new_low = 0.25 + (0.45 - 0.25) * (0.50 + 0.40) / 1`
        - `new_high = 0.25 + (0.45 - 0.25) * (0.50 + 0.40 + 0.09) / 1`
        - Yellow is in the range `[0.43, 0.448)`

    5. Fourth symbol (Disabled):
    - From previous range: `[0.43, 0.448)`
        - `new_low = 0.43 + (0.448 - 0.43) * (0.50 + 0.40 + 0.09) / 1`
        - `new_low = 0.43 + (0.448 - 0.43) * (0.50 + 0.40 + 0.09 + 0.01) / 1`
        - Green is in the range `[0.44782, 0.448)`

    The final interval is `[0.44782, 0.448)`. Any number in this range (we'll pick the lower bound, which is inclusive of 0.44782) can represent our entire sequence "Green, Red, Yellow, Disabled".

    To decode, we would start with 0.44782 and use our original probability ranges to determine which symbol it corresponds to, then update the value and repeat the process.

    In this example, we aren't saving any space by using arithmetic coding because our sample is too short to have any pattern to effectively exploit. With longer sequences, arithmetic coding approaches the theoretical entropy limit of **1.408 bits per symbol**: `-(0.50 * log2(0.50) + 0.40 * log2(0.40) + 0.09 * log2(0.09) + 0.01 * log2(0.01)) ≈ 1.408`

    It is important to note that in practice, there often are additional considerations not present in this simplified example with regard to managing precision.

4. **Prediction and Residual Encoding**:
   Prediction involves using previous data to predict future data. The difference between the predicted and actual data (residual) is encoded instead of the actual data. Linear Predictive Coding (LPC) is a common method where a linear function of previous samples is used to predict the current sample. The residuals typically have lower entropy and can be encoded more efficiently.

